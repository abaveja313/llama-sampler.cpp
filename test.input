{"python_code":"print('Hello World')", "model_path": "/Users/amrit/Desktop/StanfordAI/llm_semantics/bkcp/baseline/codellama-13b-inst.gguf", "gpu_layers": 10, "batch_threads": 10, "prompt_context_size": 1024, "upper_token_limit": 1200, "top_k": 10, "top_p": 0.90, "temp":0.5, "num_samples": 2, "use_limit": false}